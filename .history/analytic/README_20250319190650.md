
## Báo cáo Quy trình Xử lý Dữ liệu và Xây dựng Mô hình Phân loại
### 1. Giảm chiều dữ liệu bằng PCA

- **Mục tiêu:**  
  Sử dụng Phân tích thành phần chính (PCA) để giảm số chiều dữ liệu, giữ lại các thành phần chính giải thích được phần lớn phương sai (ví dụ: 95%).  
- **Lợi ích:**  
  - Giảm nhiễu và loại bỏ những đặc trưng không cần thiết.  
  - Giảm thời gian tính toán và cải thiện hiệu năng của mô hình.  
  - Giúp trực quan hóa dữ liệu trong không gian có chiều thấp hơn nếu cần thiết.

### 2. Tiền xử lý dữ liệu

- **Lấy dữ liệu số và loại bỏ giá trị thiếu:**  
  Chỉ sử dụng các cột có kiểu số và loại bỏ các dòng có giá trị thiếu để đảm bảo tính toàn vẹn của dữ liệu cho các bước xử lý tiếp theo.

- **Loại bỏ ngoại lai bằng phương pháp tứ phân vị (IQR):**  
  Áp dụng hàm lọc ngoại lai cho từng cột số bằng cách tính phần tư thứ nhất (Q1) và phần tư thứ ba (Q3), sau đó tính khoảng giữa các phần tư (IQR = Q3 - Q1).  
  - Các giá trị nằm ngoài khoảng [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] được coi là ngoại lai và bị loại bỏ.  
  - Mục tiêu là giảm sự ảnh hưởng của các giá trị bất thường đối với quá trình học của mô hình.

### 2. Chuẩn hóa dữ liệu

- **Standard Scaling:**  
  Dữ liệu được chuẩn hóa về cùng một thang đo thông qua phương pháp chuẩn hóa (StandardScaler) nhằm đảm bảo các đặc trưng có mức độ tương đồng và không ảnh hưởng do sự khác biệt về đơn vị đo lường.  
  - Điều này đặc biệt quan trọng khi thực hiện PCA và các mô hình học máy, vì các thuật toán nhạy cảm với thang đo của dữ liệu.



### 4. Cân bằng dữ liệu với SMOTE

- **Vấn đề dữ liệu không cân bằng:**  
  Khi tập dữ liệu có sự chênh lệch đáng kể giữa các lớp (ví dụ: lớp thiểu số bị thiếu nhiều mẫu), mô hình sẽ thiên về lớp chiếm đa số.
- **Giải pháp – SMOTE (Synthetic Minority Over-sampling Technique):**  
  Tạo ra các mẫu tổng hợp cho lớp thiểu số nhằm cân bằng lại tập dữ liệu, giúp mô hình học tốt hơn cả hai lớp.  
  - SMOTE giúp cải thiện độ nhạy (recall) cho lớp thiểu số và giảm thiểu hiện tượng overfitting đối với lớp chiếm đa số.

### 5. Chia tách dữ liệu thành tập huấn luyện và kiểm tra

- **Mục đích:**  
  Phân chia dữ liệu sau bước cân bằng thành tập huấn luyện và tập kiểm tra để đánh giá hiệu quả của mô hình trên dữ liệu chưa từng thấy.  
  - Thông thường, tỉ lệ chia có thể là 80% cho huấn luyện và 20% cho kiểm tra.

### 6. Xây dựng các mô hình phân loại

- **Mô hình Random Forest:**  
  - Một thuật toán dựa trên các cây quyết định (decision tree) và sử dụng phương pháp ensemble để cải thiện độ ổn định và hiệu suất dự đoán.
  - Ưu điểm: Khả năng chống overfitting tốt và hiệu quả trong việc xử lý dữ liệu với nhiều đặc trưng.
  
- **Mô hình XGBoost:**  
  - Một thuật toán boosting mạnh mẽ, thường cho hiệu quả tốt hơn trong việc tối ưu hoá hàm mất mát và xử lý các mối quan hệ phi tuyến tính.
  - Ưu điểm: Thường có hiệu suất tổng quát cao hơn và xử lý tốt các bài toán phức tạp, đặc biệt khi dữ liệu có nhiễu.

### 7. Đánh giá và so sánh hiệu suất của các mô hình

- **Các chỉ số đánh giá:**  
  - **Accuracy (Độ chính xác):** Tỷ lệ dự đoán đúng trên tổng số mẫu.  
  - **Precision (Độ chính xác của dự đoán):** Đo lường tỷ lệ mẫu được dự đoán đúng trên tổng số mẫu được dự đoán cho một lớp cụ thể.  
  - **Recall (Độ nhạy):** Đo lường khả năng nhận diện đúng các mẫu thuộc một lớp.  
  - **F1 Score:** Trung bình điều hòa giữa precision và recall, đặc biệt hữu ích khi dữ liệu không cân bằng.  
  - **Ma trận nhầm lẫn và Classification Report:** Cung cấp thông tin chi tiết về số lượng mẫu dự đoán đúng/sai cho từng lớp, giúp nhận diện rõ ràng vấn đề đối với lớp thiểu số.

- **So sánh mô hình:**  
  Qua các chỉ số trên, ta có thể nhận thấy:
  - Cả hai mô hình đều có accuracy cao, nhưng điều này có thể bị lệch khi dữ liệu không cân bằng.
  - XGBoost thường cho kết quả precision, recall và F1 score cao hơn so với Random Forest, đặc biệt đối với lớp thiểu số.
  - Ma trận nhầm lẫn và báo cáo phân loại cho thấy XGBoost có xu hướng nhận diện lớp ít mẫu tốt hơn, mặc dù vẫn còn hạn chế và cần cải thiện thêm.

